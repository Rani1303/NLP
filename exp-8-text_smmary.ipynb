{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed text:\n",
      "Tajmehal Computer science dynamic ever-evolving field encompasses study algorithms , data structures , programming languages , theoretical foundations computing . plays pivotal role shaping modern world , driving innovation across various industries . Computer scientists analyze solve complex problems , develop cutting-edge software , design efficient algorithms enhance computational capabilities . artificial intelligence machine learning cybersecurity software engineering , computer science influences nearly every aspect daily lives . technology continues advance , field computer science remains forefront , paving way transformative breakthroughs shaping digital landscape future\n",
      "\n",
      "Vectorized text:\n",
      "  (0, 33)\t0.09950371902099892\n",
      "  (0, 38)\t0.09950371902099892\n",
      "  (0, 19)\t0.09950371902099892\n",
      "  (0, 6)\t0.09950371902099892\n",
      "  (0, 62)\t0.09950371902099892\n",
      "  (0, 64)\t0.09950371902099892\n",
      "  (0, 45)\t0.09950371902099892\n",
      "  (0, 31)\t0.09950371902099892\n",
      "  (0, 50)\t0.09950371902099892\n",
      "  (0, 1)\t0.09950371902099892\n",
      "  (0, 12)\t0.09950371902099892\n",
      "  (0, 60)\t0.09950371902099892\n",
      "  (0, 41)\t0.09950371902099892\n",
      "  (0, 15)\t0.09950371902099892\n",
      "  (0, 5)\t0.09950371902099892\n",
      "  (0, 28)\t0.09950371902099892\n",
      "  (0, 44)\t0.09950371902099892\n",
      "  (0, 35)\t0.09950371902099892\n",
      "  (0, 25)\t0.09950371902099892\n",
      "  (0, 14)\t0.09950371902099892\n",
      "  (0, 40)\t0.09950371902099892\n",
      "  (0, 42)\t0.09950371902099892\n",
      "  (0, 37)\t0.09950371902099892\n",
      "  (0, 4)\t0.09950371902099892\n",
      "  (0, 7)\t0.09950371902099892\n",
      "  :\t:\n",
      "  (0, 36)\t0.09950371902099892\n",
      "  (0, 20)\t0.09950371902099892\n",
      "  (0, 65)\t0.09950371902099892\n",
      "  (0, 43)\t0.09950371902099892\n",
      "  (0, 54)\t0.19900743804199783\n",
      "  (0, 51)\t0.09950371902099892\n",
      "  (0, 46)\t0.09950371902099892\n",
      "  (0, 47)\t0.09950371902099892\n",
      "  (0, 11)\t0.09950371902099892\n",
      "  (0, 32)\t0.09950371902099892\n",
      "  (0, 61)\t0.09950371902099892\n",
      "  (0, 39)\t0.09950371902099892\n",
      "  (0, 49)\t0.09950371902099892\n",
      "  (0, 57)\t0.09950371902099892\n",
      "  (0, 16)\t0.09950371902099892\n",
      "  (0, 2)\t0.19900743804199783\n",
      "  (0, 58)\t0.09950371902099892\n",
      "  (0, 24)\t0.09950371902099892\n",
      "  (0, 30)\t0.19900743804199783\n",
      "  (0, 29)\t0.09950371902099892\n",
      "  (0, 27)\t0.09950371902099892\n",
      "  (0, 21)\t0.09950371902099892\n",
      "  (0, 52)\t0.29851115706299675\n",
      "  (0, 10)\t0.39801487608399566\n",
      "  (0, 59)\t0.09950371902099892\n",
      "\n",
      "Cosine similarity matrix for each sentence:\n",
      "[[1.]]\n",
      "\n",
      "Cosine similarity matrix for each word:\n",
      "[[1.         0.12667419 0.19450991 0.15818011 0.31131848]\n",
      " [0.12667419 1.         0.04964286 0.03351522 0.15631894]\n",
      " [0.19450991 0.04964286 1.         0.17781728 0.08553791]\n",
      " [0.15818011 0.03351522 0.17781728 1.         0.14520682]\n",
      " [0.31131848 0.15631894 0.08553791 0.14520682 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Tokenize each sentence into words\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_sentences = []\n",
    "    for sentence_tokens in word_tokens:\n",
    "        filtered_sentence = [word for word in sentence_tokens if word.lower() not in stop_words]\n",
    "        filtered_sentences.append(filtered_sentence)\n",
    "    \n",
    "    # Flatten the list of words into a single list of all words\n",
    "    all_words = [word for sentence in filtered_sentences for word in sentence]\n",
    "    \n",
    "    # Convert the list of words back to text\n",
    "    processed_text = \" \".join(all_words)\n",
    "    \n",
    "    return processed_text, sentences, word_tokens\n",
    "\n",
    "# Read text data from the .txt file\n",
    "def read_text_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "# Example .txt file path\n",
    "file_path = 'paper.txt'\n",
    "\n",
    "# Read text from the .txt file\n",
    "text = read_text_from_file(file_path)\n",
    "\n",
    "# Preprocess the text\n",
    "processed_text, sentences, word_tokens = preprocess_text(text)\n",
    "\n",
    "# Vectorize the preprocessed text\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorized_text = vectorizer.fit_transform([processed_text])\n",
    "\n",
    "# Calculate cosine similarity for each sentence\n",
    "sentence_cosine_sim = cosine_similarity(vectorized_text, vectorized_text)\n",
    "\n",
    "# Calculate cosine similarity for each word\n",
    "word_vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "word_vectorized_text = word_vectorizer.fit_transform(word_tokens)\n",
    "word_cosine_sim = cosine_similarity(word_vectorized_text, word_vectorized_text)\n",
    "\n",
    "print(\"Preprocessed text:\")\n",
    "print(processed_text)\n",
    "print(\"\\nVectorized text:\")\n",
    "print(vectorized_text)\n",
    "print(\"\\nCosine similarity matrix for each sentence:\")\n",
    "print(sentence_cosine_sim)\n",
    "print(\"\\nCosine similarity matrix for each word:\")\n",
    "print(word_cosine_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
